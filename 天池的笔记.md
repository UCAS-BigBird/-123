# <center>这是一个标题</center>>

输出最终结果  

~~~python
import pandas as pd
pd.DataFrame(final).to_csv(r'C:h\Users\UCAS_BigBird\Desktop\ouy							  ue.txt',index=False,header=False)
~~~

==metrics  参数坐标==

~~~python
param2 = {'silent':True
          ,'obj':'reg:linear'
          ,"max_depth":2
          ,'eta':0.05
          ,'gamma':2
          ,"nfold":5}
bst=xgb.train(params=param2,num_boost_round=200,dtrain=dfull)

dtest = xgb.DMatrix(test)
q=bst.predict(dtest)

import pandas as pd
pd.DataFrame(q).to_csv(r'C:\Users\UCAS_BigBird\Desktop\ouyue.txt',index=False,
                       header=False)
~~~

==上方代码证明如果顺利使用xgboost训练完的结果==



==下方代码给出了xgboost 调试的经验==

~~~python
dfull = xgb.DMatrix(train,y)
param1 = {'silent':True #并非默认
          ,'obj':'reg:linear' #并非默认
          ,"subsample":1  #随机抽样的时候抽取的样本比例
          ,"max_depth":6  #最大深度
          ,"eta":0.3      #树的迭代速率
          ,"gamma":0      #gamma是对梯度提升树影响最大的参数之一
          ,"lambda":1     #L2正则项
          ,"alpha":0      #L1正则项
          ,"colsample_bytree":1
          ,"colsample_bylevel":1
          ,"colsample_bynode":1
          ,"nfold":5}
num_round = 200
cvresult1 = xgb.cv(param1, dfull, num_round)
print('完全是OK的！')

fig,ax = plt.subplots(1,figsize=(15,8))
#ax.set_ylim(top=5)
ax.grid()
ax.plot(range(1,201),cvresult1.iloc[:,0],c="red",label="train,original")
ax.plot(range(1,201),cvresult1.iloc[:,2],c="orange",label="test,original")
ax.legend(fontsize="xx-large")
plt.show()
~~~

==RMSE==计算公式如下 同时==MSE==计算公式如下
$$
RMSE(X,h)=\sqrt{\frac{1}{m}\sum_{i=1}^{m}(h(x_i)-y_i)^2}\\
MSE(X,h)={\frac{1}{m}\sum_{i=1}^{m}(h(x_i)-y_i)^2}
$$
千万不要这也想 那也想 结果最基础的都不会！

**利用np.mean即可处理解决这个问题**

~~~python
def calculate_mse(y_predict,y_real):
    return np.mean((np.array(y_predict)-np.array(y_real))**2)
~~~

==如何获取列表的最大最小值索引==

~~~python
a.index(min(a))
#获得最小的索引
a.index(max(a))
#获得最大的索引
~~~

==决策树中非常重要的一个计算方法==

~~~python
[*zip(xtrain.columns),clf.feature_importances]
~~~

5 6 9 10 11 12 13 14 15 16 17 18 19 20 22 24 26 28 29 30 32 34 35 36 37

~~~python
param2 = {'silent':True
          ,'obj':'reg:linear'
          ,"max_depth":2
          ,'eta':0.05
          ,'gamma':2
          ,'lambda':1
           ,'alpha':0
          ,"colsample_bytree":1
          ,"colsample_bylevel":1
          ,"nfold":5}
#这是调试出来最好的参数
~~~

